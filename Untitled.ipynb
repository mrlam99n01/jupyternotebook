{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def mkdir_if_not_exist(path):  #@save\n",
    "    \"\"\"Make a directory if it does not exist.\"\"\"\n",
    "    if not isinstance(path, str):\n",
    "        path = os.path.join(*path)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "763           10      101             76             48      180  32.9   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "766            1      126             60              0        0  30.1   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                       0.627   50        1  \n",
      "1                       0.351   31        0  \n",
      "2                       0.672   32        1  \n",
      "3                       0.167   21        0  \n",
      "4                       2.288   33        1  \n",
      "..                        ...  ...      ...  \n",
      "763                     0.171   63        0  \n",
      "764                     0.340   27        0  \n",
      "765                     0.245   30        0  \n",
      "766                     0.349   47        1  \n",
      "767                     0.315   23        0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_file = '/home/lam/Downloads/archive/diabetes.csv'\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 748.8 MB 1.8 kB/s eta 0:00:01    |██▍                             | 56.8 MB 1.8 MB/s eta 0:06:33     |███▎                            | 76.5 MB 1.9 MB/s eta 0:06:01     |███████▏                        | 166.5 MB 2.8 MB/s eta 0:03:25     |████████████▏                   | 285.8 MB 3.6 MB/s eta 0:02:11     |████████████▊                   | 297.1 MB 3.0 MB/s eta 0:02:30     |████████████████▎               | 380.8 MB 4.6 MB/s eta 0:01:21     |████████████████▍               | 383.3 MB 5.0 MB/s eta 0:01:14     |█████████████████▏              | 401.2 MB 4.9 MB/s eta 0:01:12     |████████████████████            | 468.1 MB 3.4 MB/s eta 0:01:23     |███████████████████████████     | 634.0 MB 1.5 MB/s eta 0:01:16     |████████████████████████████▋   | 670.2 MB 2.2 MB/s eta 0:00:35     |█████████████████████████████   | 677.7 MB 2.6 MB/s eta 0:00:28     |█████████████████████████████▏  | 683.8 MB 2.5 MB/s eta 0:00:27     |█████████████████████████████▎  | 686.3 MB 2.3 MB/s eta 0:00:27\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 189 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./my_project_env/lib/python3.7/site-packages (from torch) (1.19.2)\n",
      "Collecting pillow>=4.1.1\n",
      "  Downloading Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=076e8a5cdb3443a343f32f0c7a1786799e6177150dad333af1f5b02c3e1c0280\n",
      "  Stored in directory: /home/lam/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "Successfully built future\n",
      "Installing collected packages: future, torch, pillow, torchvision\n",
      "Successfully installed future-0.18.2 pillow-7.2.0 torch-1.6.0 torchvision-0.7.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/lam/my_project_dir/my_project_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch torchvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose\n",
      "0              6      148\n",
      "1              1       85\n",
      "2              8      183\n",
      "3              1       89\n",
      "4              0      137\n",
      "..           ...      ...\n",
      "763           10      101\n",
      "764            2      122\n",
      "765            5      121\n",
      "766            1      126\n",
      "767            1       93\n",
      "\n",
      "[768 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  6, 148],\n",
       "         [  1,  85],\n",
       "         [  8, 183],\n",
       "         ...,\n",
       "         [  5, 121],\n",
       "         [  1, 126],\n",
       "         [  1,  93]]),\n",
       " tensor([ 72,  66,  64,  66,  40,  74,  50,   0,  70,  96,  92,  74,  80,  60,\n",
       "          72,   0,  84,  74,  30,  70,  88,  84,  90,  80,  94,  70,  76,  66,\n",
       "          82,  92,  75,  76,  58,  92,  78,  60,  76,  76,  68,  72,  64,  84,\n",
       "          92, 110,  64,  66,  56,  70,  66,   0,  80,  50,  66,  90,  66,  50,\n",
       "          68,  88,  82,  64,   0,  72,  62,  58,  66,  74,  88,  92,  66,  85,\n",
       "          66,  64,  90,  86,  75,  48,  78,  72,   0,  66,  44,   0,  78,  65,\n",
       "         108,  74,  72,  68,  70,  68,  55,  80,  78,  72,  82,  72,  62,  48,\n",
       "          50,  90,  72,  60,  96,  72,  65,  56, 122,  58,  58,  85,  72,  62,\n",
       "          76,  62,  54,  92,  74,  48,  60,  76,  76,  64,  74,  80,  76,  30,\n",
       "          70,  58,  88,  84,  70,  56,  64,  74,  68,  60,  70,  60,  80,  72,\n",
       "          78,  82,  52,  66,  62,  75,  80,  64,  78,  70,  74,  65,  86,  82,\n",
       "          78,  88,  52,  56,  74,  72,  90,  74,  80,  64,  88,  74,  66,  68,\n",
       "          66,  90,  82,  70,   0,  60,  64,  72,  78, 110,  78,  82,  80,  64,\n",
       "          74,  60,  74,  68,  68,  98,  76,  80,  62,  70,  66,   0,  55,  84,\n",
       "          58,  62,  64,  60,  80,  82,  68,  70,  72,  72,  76, 104,  64,  84,\n",
       "          60,  85,  95,  65,  82,  70,  62,  68,  74,  66,  60,  90,   0,  60,\n",
       "          66,  78,  76,  52,  70,  80,  86,  80,  80,  68,  68,  72,  84,  90,\n",
       "          84,  76,  64,  70,  54,  50,  76,  85,  68,  90,  70,  86,  52,  84,\n",
       "          80,  68,  62,  64,  56,  68,  50,  76,  68,   0,  70,  80,  62,  74,\n",
       "           0,  64,  52,   0,  86,  62,  78,  78,  70,  70,  60,  64,  74,  62,\n",
       "          70,  76,  88,  86,  80,  74,  84,  86,  56,  72,  88,  62,  78,  48,\n",
       "          50,  62,  70,  84,  78,  72,   0,  58,  82,  98,  76,  76,  68,  68,\n",
       "          68,  68,  66,  70,  74,  50,  80,  68,  80,  74,  66,  78,  60,  74,\n",
       "          70,  90,  75,  72,  64,  70,  86,  70,  72,  58,   0,  80,  60,  76,\n",
       "           0,  76,  78,  84,  70,  74,  68,  86,  72,  88,  46,   0,  62,  80,\n",
       "          80,  84,  82,  62,  78,  88,  50,   0,  74,  76,  64,  70, 108,  78,\n",
       "          74,  54,  72,  64,  86, 102,  82,  64,  64,  58,  52,  82,  82,  60,\n",
       "          75, 100,  72,  68,  60,  62,  70,  54,  74, 100,  82,  68,  66,  76,\n",
       "          64,  72,  78,  58,  56,  66,  70,  70,  64,  61,  84,  78,  64,  48,\n",
       "          72,  62,  74,  68,  90,  72,  84,  74,  60,  84,  68,  82,  68,  64,\n",
       "          88,  68,  64,  64,  78,  78,   0,  64,  94,  82,   0,  74,  74,  75,\n",
       "          68,   0,  85,  75,  70,  88, 104,  66,  64,  70,  62,  78,  72,  80,\n",
       "          64,  74,  64,  70,  68,   0,  54,  62,  54,  68,  84,  74,  72,  62,\n",
       "          70,  78,  98,  56,  52,  64,   0,  78,  82,  70,  66,  90,  64,  84,\n",
       "          80,  76,  74,  86,  70,  88,  58,  82,   0,  68,  62,  78,  72,  80,\n",
       "          65,  90,  68,  70,   0,  74,  68,  72,  70,  74,  90,  72,  68,  64,\n",
       "          78,  82,  90,  60,  50,  78,  72,  62,  68,  62,  54,  70,  88,  86,\n",
       "          60,  90,  70,  80,   0,  70,  58,  60,  64,  74,  66,  65,  60,  76,\n",
       "          66,   0,  56,   0,  90,  60,  80,  92,  74,  72,  85,  90,  78,  90,\n",
       "          76,  68,  82, 110,  70,  68,  88,  62,  64,  70,  70,  76,  68,  74,\n",
       "          76,  66,  68,  60,  80,  54,  72,  62,  72,  66,  70,  96,  58,  60,\n",
       "          86,  44,  44,  80,  68,  70,  90,  60,  78,  76,  76,  56,  66,  66,\n",
       "          86,   0,  84,  78,  80,  52,  72,  82,  76,  24,  74,  38,  88,   0,\n",
       "          74,  78,   0,  60,  78,  62,  82,  62,  54,  58,  88,  80,  74,  72,\n",
       "          96,  62,  82,   0,  86,  76,  94,  70,  64,  88,  68,  78,  80,  65,\n",
       "          64,  78,  60,  82,  62,  72,  74,  76,  76,  74,  86,  70,  80,   0,\n",
       "          72,  74,  74,  50,  84,  60,  54,  60,  74,  54,  70,  52,  58,  80,\n",
       "         106,  82,  84,  76, 106,  80,  60,  80,  82,  70,  58,  78,  68,  58,\n",
       "         106, 100,  82,  70,  86,  60,  52,  58,  56,  76,  64,  80,  82,  74,\n",
       "          64,  50,  74,  82,  80, 114,  70,  68,  60,  90,  74,   0,  88,  70,\n",
       "          76,  78,  88,   0,  76,  80,   0,  46,  78,  64,  64,  78,  62,  58,\n",
       "          74,  50,  78,  72,  60,  76,  86,  66,  68,  86,  94,  78,  78,  84,\n",
       "          88,  52,  78,  86,  88,  56,  75,  60,  86,  72,  60,  74,  80,  44,\n",
       "          58,  94,  88,  84,  94,  74,  70,  62,  70,  78,  62,  88,  78,  88,\n",
       "          90,  72,  76,  92,  58,  74,  62,  76,  70,  72,  60,  70]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([3.0])\n",
    "y = torch.tensor([2.0])\n",
    "x = torch.arange(4)\n",
    "x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5, 4)\n",
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "B == B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(-1, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 22, 38, 54, 70, 86])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "B = A.clone()  # Assign a copy of `A` to `B` by allocating new memory\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[[1],]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "n = 10\n",
    "m =20\n",
    "p =30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 30])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tensor1 = torch.rand((batch,n,m))\n",
    "tensor2 = torch.rand((batch,m,p))\n",
    "out_bmm = torch.bmm(tensor1,tensor2)\n",
    "out_bmm.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor([[5,1,6,7],[1,2,3,8],[12,22,3,8]])\n",
    "x2 = torch.tensor([5,5,4,3])\n",
    "z = x1-x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 22,  6,  8])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_x = torch.sum(x1,dim=1)\n",
    "values, indices = torch.max(x1,dim = 0)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  1,  6,  7],\n",
       "        [ 1,  2,  3,  8],\n",
       "        [12, 22,  3,  8]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_x = torch.abs(x1)\n",
    "abs_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 0, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch. argmax(x1,axis=0)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.sort(\n",
      "values=tensor([[12, 22,  6,  8],\n",
      "        [ 5,  2,  3,  8],\n",
      "        [ 1,  1,  3,  7]]),\n",
      "indices=tensor([[2, 2, 0, 1],\n",
      "        [0, 1, 1, 2],\n",
      "        [1, 0, 2, 0]]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.sort(x1, dim = 0, descending = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  1,  6,  7],\n",
       "        [ 1,  2,  3,  8],\n",
       "        [12, 22,  3,  8]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.clamp(x1,min=2)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,0,1,1], dtype=torch.bool)\n",
    "z = torch.any(x)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0028, 0.1408, 0.5069, 0.1500, 0.3962],\n",
       "        [0.5275, 0.0912, 0.9722, 0.8549, 0.5763],\n",
       "        [0.4900, 0.7792, 0.3814, 0.4332, 0.4086],\n",
       "        [0.0682, 0.2584, 0.7034, 0.7072, 0.0458],\n",
       "        [0.3286, 0.6236, 0.3036, 0.5680, 0.5487]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "features = 5\n",
    "x = torch.rand((batch_size,features))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0028, 0.1408, 0.5069, 0.1500, 0.3962])\n"
     ]
    }
   ],
   "source": [
    "print(x[0].shape) #x[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4900, 0.7792, 0.3814, 0.4332, 0.4086])\n"
     ]
    }
   ],
   "source": [
    "print(x[2, 0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9016, 0.2778, 0.4420, 0.1022, 0.6446],\n",
      "        [0.8280, 0.4863, 0.2029, 0.4484, 0.1117],\n",
      "        [0.0710, 0.2849, 0.1061, 0.9927, 0.6038]])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((3,5))\n",
    "indicies = [2,5,8]\n",
    "rows = torch.tensor([1,0])\n",
    "cols = torch.tensor([1,0])\n",
    "print(x)\n",
    "print(x[rows,cols].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], dtype=torch.int64)\n",
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "print(x[(x<2)&(x>8)])\n",
    "print(x[x.remainder(2) ==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  2,  4,  6,  8, 10,  6,  7,  8,  9])\n"
     ]
    }
   ],
   "source": [
    "print(torch.where(x>5,x,x*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([0,0,0,1,2,3,2,3]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(x1.numel())\n",
    "print(x1.ndimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(9)\n",
    "x_3x3 = x.reshape(3,3)\n",
    "x_3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 6],\n",
       "        [1, 4, 7],\n",
       "        [2, 5, 8]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x_3x3.t()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat((x,x),dim = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "batch = 64\n",
    "x = torch.rand((batch,2,5))\n",
    "z = x.view(batch,-1)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7953, 0.9617],\n",
       "         [0.5867, 0.2243],\n",
       "         [0.3907, 0.3930],\n",
       "         [0.9747, 0.0992],\n",
       "         [0.8438, 0.2896]],\n",
       "\n",
       "        [[0.2808, 0.1314],\n",
       "         [0.3719, 0.3012],\n",
       "         [0.5415, 0.6295],\n",
       "         [0.8396, 0.2363],\n",
       "         [0.5163, 0.0558]],\n",
       "\n",
       "        [[0.9253, 0.6394],\n",
       "         [0.3450, 0.0575],\n",
       "         [0.2962, 0.9154],\n",
       "         [0.2299, 0.7340],\n",
       "         [0.1414, 0.0500]],\n",
       "\n",
       "        [[0.3490, 0.1448],\n",
       "         [0.7799, 0.2572],\n",
       "         [0.7416, 0.1872],\n",
       "         [0.3887, 0.3190],\n",
       "         [0.2510, 0.2936]],\n",
       "\n",
       "        [[0.1747, 0.3357],\n",
       "         [0.0661, 0.5801],\n",
       "         [0.8332, 0.1903],\n",
       "         [0.2823, 0.3538],\n",
       "         [0.4657, 0.8546]],\n",
       "\n",
       "        [[0.8400, 0.3681],\n",
       "         [0.1979, 0.1518],\n",
       "         [0.4522, 0.8806],\n",
       "         [0.2183, 0.2499],\n",
       "         [0.6486, 0.2507]],\n",
       "\n",
       "        [[0.5194, 0.8187],\n",
       "         [0.5195, 0.1116],\n",
       "         [0.6807, 0.3874],\n",
       "         [0.1206, 0.9137],\n",
       "         [0.5908, 0.9133]],\n",
       "\n",
       "        [[0.0980, 0.9285],\n",
       "         [0.8379, 0.4219],\n",
       "         [0.8170, 0.2441],\n",
       "         [0.8316, 0.5072],\n",
       "         [0.2519, 0.9013]],\n",
       "\n",
       "        [[0.9589, 0.1782],\n",
       "         [0.8649, 0.7467],\n",
       "         [0.9091, 0.7046],\n",
       "         [0.1804, 0.4502],\n",
       "         [0.3499, 0.6031]],\n",
       "\n",
       "        [[0.5020, 0.6353],\n",
       "         [0.6477, 0.3070],\n",
       "         [0.9653, 0.6364],\n",
       "         [0.9305, 0.2914],\n",
       "         [0.7699, 0.0568]],\n",
       "\n",
       "        [[0.2680, 0.2494],\n",
       "         [0.6853, 0.5339],\n",
       "         [0.7363, 0.0587],\n",
       "         [0.8710, 0.1823],\n",
       "         [0.3961, 0.8633]],\n",
       "\n",
       "        [[0.5552, 0.1103],\n",
       "         [0.3531, 0.7693],\n",
       "         [0.9361, 0.3437],\n",
       "         [0.0075, 0.7517],\n",
       "         [0.7173, 0.2059]],\n",
       "\n",
       "        [[0.4173, 0.4181],\n",
       "         [0.9211, 0.4860],\n",
       "         [0.4820, 0.1025],\n",
       "         [0.5541, 0.9646],\n",
       "         [0.8675, 0.2466]],\n",
       "\n",
       "        [[0.6477, 0.1074],\n",
       "         [0.8899, 0.4823],\n",
       "         [0.1625, 0.4992],\n",
       "         [0.6950, 0.9394],\n",
       "         [0.2598, 0.9753]],\n",
       "\n",
       "        [[0.7035, 0.7097],\n",
       "         [0.2982, 0.4133],\n",
       "         [0.3244, 0.8499],\n",
       "         [0.5112, 0.3947],\n",
       "         [0.3938, 0.5301]],\n",
       "\n",
       "        [[0.4907, 0.4870],\n",
       "         [0.0497, 0.2857],\n",
       "         [0.5700, 0.9158],\n",
       "         [0.9813, 0.7656],\n",
       "         [0.7267, 0.9006]],\n",
       "\n",
       "        [[0.0323, 0.1558],\n",
       "         [0.8656, 0.2143],\n",
       "         [0.0409, 0.0205],\n",
       "         [0.4554, 0.5163],\n",
       "         [0.0460, 0.8685]],\n",
       "\n",
       "        [[0.9724, 0.1958],\n",
       "         [0.1358, 0.3174],\n",
       "         [0.3498, 0.0367],\n",
       "         [0.0707, 0.3342],\n",
       "         [0.6880, 0.0093]],\n",
       "\n",
       "        [[0.7591, 0.0165],\n",
       "         [0.4793, 0.7921],\n",
       "         [0.1118, 0.6661],\n",
       "         [0.3804, 0.1735],\n",
       "         [0.0110, 0.5343]],\n",
       "\n",
       "        [[0.5994, 0.6213],\n",
       "         [0.8811, 0.9395],\n",
       "         [0.4716, 0.2983],\n",
       "         [0.9774, 0.7940],\n",
       "         [0.4120, 0.9907]],\n",
       "\n",
       "        [[0.8620, 0.5773],\n",
       "         [0.3745, 0.1393],\n",
       "         [0.7124, 0.2463],\n",
       "         [0.4275, 0.2423],\n",
       "         [0.1676, 0.4056]],\n",
       "\n",
       "        [[0.8656, 0.4887],\n",
       "         [0.3383, 0.9306],\n",
       "         [0.4165, 0.0114],\n",
       "         [0.0847, 0.2628],\n",
       "         [0.8582, 0.9274]],\n",
       "\n",
       "        [[0.4301, 0.5092],\n",
       "         [0.2651, 0.9242],\n",
       "         [0.2323, 0.8706],\n",
       "         [0.5014, 0.3186],\n",
       "         [0.8346, 0.0021]],\n",
       "\n",
       "        [[0.2208, 0.0299],\n",
       "         [0.1684, 0.6647],\n",
       "         [0.7922, 0.1086],\n",
       "         [0.1127, 0.9603],\n",
       "         [0.8410, 0.1643]],\n",
       "\n",
       "        [[0.6473, 0.0509],\n",
       "         [0.3865, 0.3429],\n",
       "         [0.5393, 0.9136],\n",
       "         [0.2856, 0.3683],\n",
       "         [0.8832, 0.5217]],\n",
       "\n",
       "        [[0.7774, 0.0359],\n",
       "         [0.2510, 0.6927],\n",
       "         [0.0501, 0.7334],\n",
       "         [0.3256, 0.9359],\n",
       "         [0.3554, 0.8324]],\n",
       "\n",
       "        [[0.4503, 0.9007],\n",
       "         [0.0828, 0.4587],\n",
       "         [0.2968, 0.4086],\n",
       "         [0.5187, 0.9926],\n",
       "         [0.2537, 0.1931]],\n",
       "\n",
       "        [[0.6135, 0.2689],\n",
       "         [0.7804, 0.7795],\n",
       "         [0.9369, 0.3996],\n",
       "         [0.6695, 0.8118],\n",
       "         [0.7713, 0.7721]],\n",
       "\n",
       "        [[0.1258, 0.8190],\n",
       "         [0.3436, 0.6730],\n",
       "         [0.9514, 0.5814],\n",
       "         [0.7728, 0.3470],\n",
       "         [0.2237, 0.2457]],\n",
       "\n",
       "        [[0.4485, 0.9277],\n",
       "         [0.1022, 0.2460],\n",
       "         [0.4572, 0.5090],\n",
       "         [0.2974, 0.4378],\n",
       "         [0.1693, 0.8194]],\n",
       "\n",
       "        [[0.6383, 0.4551],\n",
       "         [0.8033, 0.7240],\n",
       "         [0.7313, 0.0419],\n",
       "         [0.1803, 0.9467],\n",
       "         [0.5369, 0.4586]],\n",
       "\n",
       "        [[0.8336, 0.1975],\n",
       "         [0.8418, 0.1430],\n",
       "         [0.8735, 0.8109],\n",
       "         [0.5091, 0.3871],\n",
       "         [0.4838, 0.1327]],\n",
       "\n",
       "        [[0.9110, 0.1292],\n",
       "         [0.2999, 0.9470],\n",
       "         [0.1155, 0.6991],\n",
       "         [0.4219, 0.5912],\n",
       "         [0.0320, 0.9115]],\n",
       "\n",
       "        [[0.7529, 0.7110],\n",
       "         [0.0632, 0.5457],\n",
       "         [0.4795, 0.4185],\n",
       "         [0.7589, 0.1626],\n",
       "         [0.0223, 0.4611]],\n",
       "\n",
       "        [[0.5315, 0.4099],\n",
       "         [0.2396, 0.2013],\n",
       "         [0.9127, 0.7263],\n",
       "         [0.4359, 0.9780],\n",
       "         [0.2506, 0.9769]],\n",
       "\n",
       "        [[0.3517, 0.0461],\n",
       "         [0.2911, 0.6494],\n",
       "         [0.5565, 0.3875],\n",
       "         [0.3827, 0.4933],\n",
       "         [0.4836, 0.7304]],\n",
       "\n",
       "        [[0.8771, 0.0948],\n",
       "         [0.3669, 0.3471],\n",
       "         [0.3520, 0.4055],\n",
       "         [0.6012, 0.1806],\n",
       "         [0.6302, 0.7029]],\n",
       "\n",
       "        [[0.5257, 0.5215],\n",
       "         [0.0627, 0.4819],\n",
       "         [0.3935, 0.7011],\n",
       "         [0.3823, 0.4679],\n",
       "         [0.5850, 0.5060]],\n",
       "\n",
       "        [[0.5289, 0.2725],\n",
       "         [0.6656, 0.8423],\n",
       "         [0.1920, 0.0396],\n",
       "         [0.9082, 0.5010],\n",
       "         [0.4112, 0.4823]],\n",
       "\n",
       "        [[0.1464, 0.3681],\n",
       "         [0.3367, 0.1615],\n",
       "         [0.9660, 0.7313],\n",
       "         [0.4156, 0.5698],\n",
       "         [0.3394, 0.9996]],\n",
       "\n",
       "        [[0.9306, 0.3466],\n",
       "         [0.2236, 0.4553],\n",
       "         [0.2887, 0.4152],\n",
       "         [0.7915, 0.8290],\n",
       "         [0.2415, 0.3107]],\n",
       "\n",
       "        [[0.0940, 0.2365],\n",
       "         [0.9144, 0.5068],\n",
       "         [0.7162, 0.7167],\n",
       "         [0.0703, 0.3160],\n",
       "         [0.9944, 0.9820]],\n",
       "\n",
       "        [[0.4534, 0.9718],\n",
       "         [0.5779, 0.8951],\n",
       "         [0.1226, 0.2353],\n",
       "         [0.7949, 0.2148],\n",
       "         [0.7350, 0.2307]],\n",
       "\n",
       "        [[0.4208, 0.5240],\n",
       "         [0.9194, 0.9062],\n",
       "         [0.8325, 0.0460],\n",
       "         [0.8512, 0.7356],\n",
       "         [0.7303, 0.9722]],\n",
       "\n",
       "        [[0.4094, 0.0950],\n",
       "         [0.6229, 0.4151],\n",
       "         [0.8248, 0.3109],\n",
       "         [0.0612, 0.4380],\n",
       "         [0.1794, 0.5220]],\n",
       "\n",
       "        [[0.3059, 0.4482],\n",
       "         [0.3215, 0.7206],\n",
       "         [0.2297, 0.1293],\n",
       "         [0.1285, 0.6721],\n",
       "         [0.8815, 0.8108]],\n",
       "\n",
       "        [[0.6491, 0.9423],\n",
       "         [0.8401, 0.7278],\n",
       "         [0.5345, 0.1622],\n",
       "         [0.3458, 0.0784],\n",
       "         [0.4569, 0.7175]],\n",
       "\n",
       "        [[0.4956, 0.3511],\n",
       "         [0.3407, 0.3145],\n",
       "         [0.2803, 0.7194],\n",
       "         [0.6331, 0.9932],\n",
       "         [0.2226, 0.0756]],\n",
       "\n",
       "        [[0.4600, 0.9309],\n",
       "         [0.4564, 0.3726],\n",
       "         [0.6150, 0.3805],\n",
       "         [0.2795, 0.9612],\n",
       "         [0.4015, 0.0116]],\n",
       "\n",
       "        [[0.9274, 0.7841],\n",
       "         [0.3792, 0.8086],\n",
       "         [0.2559, 0.0359],\n",
       "         [0.2301, 0.0160],\n",
       "         [0.9120, 0.4310]],\n",
       "\n",
       "        [[0.3758, 0.0829],\n",
       "         [0.2451, 0.1176],\n",
       "         [0.5722, 0.5399],\n",
       "         [0.7303, 0.8201],\n",
       "         [0.1190, 0.5958]],\n",
       "\n",
       "        [[0.9659, 0.3345],\n",
       "         [0.2291, 0.9362],\n",
       "         [0.4907, 0.3655],\n",
       "         [0.6215, 0.7427],\n",
       "         [0.5490, 0.9926]],\n",
       "\n",
       "        [[0.1597, 0.7150],\n",
       "         [0.0355, 0.2684],\n",
       "         [0.4107, 0.3105],\n",
       "         [0.8739, 0.6591],\n",
       "         [0.5461, 0.7532]],\n",
       "\n",
       "        [[0.5658, 0.5084],\n",
       "         [0.7656, 0.0971],\n",
       "         [0.4884, 0.7600],\n",
       "         [0.7643, 0.7915],\n",
       "         [0.6272, 0.8950]],\n",
       "\n",
       "        [[0.0463, 0.1176],\n",
       "         [0.9004, 0.7857],\n",
       "         [0.5537, 0.6031],\n",
       "         [0.1957, 0.4327],\n",
       "         [0.7448, 0.1988]],\n",
       "\n",
       "        [[0.4230, 0.1469],\n",
       "         [0.6819, 0.5985],\n",
       "         [0.7613, 0.1118],\n",
       "         [0.5192, 0.1865],\n",
       "         [0.6094, 0.2017]],\n",
       "\n",
       "        [[0.1649, 0.4699],\n",
       "         [0.6615, 0.1844],\n",
       "         [0.9857, 0.3349],\n",
       "         [0.1149, 0.0931],\n",
       "         [0.3865, 0.7310]],\n",
       "\n",
       "        [[0.6537, 0.7579],\n",
       "         [0.6450, 0.7655],\n",
       "         [0.0788, 0.9031],\n",
       "         [0.1299, 0.5837],\n",
       "         [0.8144, 0.6323]],\n",
       "\n",
       "        [[0.0603, 0.2772],\n",
       "         [0.6635, 0.2881],\n",
       "         [0.8274, 0.2142],\n",
       "         [0.6689, 0.8572],\n",
       "         [0.6728, 0.6617]],\n",
       "\n",
       "        [[0.0318, 0.3000],\n",
       "         [0.7383, 0.9386],\n",
       "         [0.6573, 0.0303],\n",
       "         [0.6476, 0.3644],\n",
       "         [0.2754, 0.3765]],\n",
       "\n",
       "        [[0.5898, 0.5593],\n",
       "         [0.7733, 0.9192],\n",
       "         [0.5648, 0.2285],\n",
       "         [0.1390, 0.1194],\n",
       "         [0.7584, 0.2897]],\n",
       "\n",
       "        [[0.3596, 0.1476],\n",
       "         [0.7187, 0.5313],\n",
       "         [0.4051, 0.1344],\n",
       "         [0.3454, 0.8654],\n",
       "         [0.4545, 0.8967]],\n",
       "\n",
       "        [[0.3267, 0.5032],\n",
       "         [0.9126, 0.2152],\n",
       "         [0.1711, 0.6671],\n",
       "         [0.4162, 0.3113],\n",
       "         [0.9576, 0.3948]],\n",
       "\n",
       "        [[0.1048, 0.4281],\n",
       "         [0.4404, 0.4992],\n",
       "         [0.5995, 0.2010],\n",
       "         [0.6212, 0.1503],\n",
       "         [0.0522, 0.0593]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.permute(0,2,1) # vi tri cua batch, 5, 2 o ben tren\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
